========================
Ready-made khmer scripts
========================

k-mer counting
==============

load-into-counting.py: build a counting hash.

   Usage::

	load-into-counting.py [ options ] <output.kh> <file1> <file2> ...

   Build a counting hash table using the sequences in <file1-N>, and save it
   to <output.kh>.

   Example::

	scripts/load-into-counting.py -k 20 -x 5e7 out.kh data/100k-filtered.fa

filter-abund.py: trim sequences at a min k-mer abundance.

   Usage::
	
	filter-abund.py [ -C <cutoff> ] <input.kh> <file1> <file2> ...

   Load a counting hash table from <input.kh> and use it to trim the
   sequences in <file1-N>.  Trimmed sequences will be placed in
   <fileN>.abundfilt.

   Example::

	scripts/load-into-counting.py -k 20 -x 5e7 table.kh data/100k-filtered.fa
	scripts/filter-abund.py -C 2 table.kh data/100k-filtered.fa

Partitioning
============

load-graph.py: load sequences into the compressible graph format.

   Usage::

        load-graph.py [ options ] <graphbase> <file1> [ <file2> ... ]

   Load in a set of sequences, marking waypoints as you go, and save
   into a ht/tagset pair of files.  See 'extract-partitions' for a
   complete workflow.

partition-graph.py: partition a graph based on waypoint connectivity.

   Usage::

	partition-graph.py [ options ] <graphbase>

   Partition the given graph (ht + tagset) into disconnected subgraphs,
   and save the resulting partitionmap(s) as *.pmap files.

merge-partitions.py: merge pmap files into a single merged pmap file.

   Usage::

        merge-partitions.py [ options ] <graphbase>

   Take the <graphbase>.subset.N.pmap files and merge them all into a
   single <graphbase>.pmap.merged file for annotate-partitions to use.

annotate-partitions.py: annotate sequences with partition IDs.

   Usage::

	annotate-partitions.py [ -k <ksize> ] <pmap.merged> <file1> [ <file2> ... ]

   Load in a partitionmap (generally produced by
   partition-graph.py/merge-partitins.py) and annotate the sequences
   in the given files with their partition IDs.  Use
   'extract-partitions.py' to actually extract sequences into separate
   group files.

   Example (results will be in ``random-20-a.fa.part``)::

	scripts/load-graph.py -k 20 example tests/test-data/random-20-a.fa
	scripts/partition-graph.py example
	scripts/merge-partitions.py -k 20 example
	scripts/annotate-partitions.py -k 20 example tests/test-data/random-20-a.fa

extract-partitions.py: separate sequences annotated with partitions into group files

   Usage::

	extract-partitions.py [ options ] <prefix> <file1.part> [ <file2.part> ... ]

   Example (results will be in ``example.group0000.fa``)::

	scripts/load-graph.py -k 20 example tests/test-data/random-20-a.fa
	scripts/partition-graph.py example
	scripts/merge-partitions.py -k 20 example
	scripts/annotate-partitions.py -k 20 example tests/test-data/random-20-a.fa
	scripts/extract-partitions.py example random-20-a.fa.part


filter-stoptags.py: trim sequences at stoptags.

   Usage::

	filter-stoptags.py [ -k <ksize> ] <input.stoptags> <file1> [ <file2> ... ]

   Load stoptags in from the given .stoptags file and use them to trim
   or remove the sequences in <file1-N>.  Trimmed sequences will be placed in
   <fileN>.stopfilt.

   (Stoptags are produced by various (re)partitioning scripts.)

Digital normalization
=====================

normalize-by-min.py: do digital normalization (remove entirely
redundant sequences)

   Usage::

	normalize-by-min.py [ options ] <file1> <file2> ...

   Discard sequences based on whether or not their **minimum** k-mer
   abundance lies above a specified cutoff.  Kept sequences will be
   placed in <fileN>.keep.

   Note: this is, in theory, a loss-less operation.  Only sequences that
   contribute no novel k-mers will be discarded.

   Example::

	scripts/normalize-by-min.py -k 17 tests/test-data/test-abund-read-2.fa

normalize-by-median.py: do digital normalization (remove mostly
redundant sequences)

   Usage::

	normalize-by-median.py [ options ] <file1> <file2> ...

   Discard sequences based on whether or not their **median** k-mer
   abundance lies above a specified cutoff.  Kept sequences will be
   placed in <fileN>.keep.

   Example::

	scripts/normalize-by-min.py -k 17 tests/test-data/test-abund-read-2.fa
